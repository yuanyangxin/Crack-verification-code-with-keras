# Use deep learning to crack verification code

This project is to crack verification code generated by captcha using keras. It is recommended to ues GPU to run the project.

# captcha

Captcha is a library of generated verification codes written in Python. It supports image verification code and voice verification code. We use it to generate image verification code.
First , we set the format  of our verification code to numbers and letters, and generate a bunch of verification codes:

```py
from captcha.image import ImageCaptcha
import matplotlib.pyplot as plt
import numpy as np
import random

%matplotlib inline
%config InlineBackend.figure_format = 'retina'

import string
characters = string.digits + string.ascii_uppercase
print(characters)

width, height, n_len, n_class = 170, 80, 4, len(characters)

generator = ImageCaptcha(width=width, height=height)
random_str = ''.join([random.choice(characters) for j in range(4)])
img = generator.generate_image(random_str)

plt.imshow(img)
plt.title(random_str)

```

![](https://raw.githubusercontent.com/ypwhs/resources/master/captcha/captcha.png)

# Data Generator

When training the model, we can choose two ways to generate our training data. One is to generate tens of thousands of images at a time, then start training. One is to define a data generator and then use the `fit_generator` function to train. .

The advantage of the first method is that the graphics card is highly utilized during training. If you need to adjust the parameters frequently, you can generate it once and use it multiple times. The advantage of the second method is that you don't need to generate a lot of data, you can use the CPU during training. Generate data, and one more benefit is that you can generate data indefinitely.

Our data format is as follows:

## X

The shape of X is `(batch_size, height, width, 3)`. For example, a batch of 32 samples is generated. The width of the image is 170 and the height is 80. Then the shape is `(32, 80, 170, 3)`. To take the first picture, we can use `X[0]`.

## y

The shape of y is `(batch_size, n_class)`. If converted to numpy format, it is `(n_len, batch_size, n_class)`, for example, a batch of 32 samples is generated, and there are 36 kinds of characters of the verification code. It is 4 bits, then its shape is 4 `(32, 36)`, which can be said to be `(4, 32, 36)`, and the decoding function is in the next block of code.

```py
def gen(batch_size=32):
    X = np.zeros((batch_size, height, width, 3), dtype=np.uint8)
    y = [np.zeros((batch_size, n_class), dtype=np.uint8) for i in range(n_len)]
    generator = ImageCaptcha(width=width, height=height)
    while True:
        for i in range(batch_size):
            random_str = ''.join([random.choice(characters) for j in range(4)])
            X[i] = generator.generate_image(random_str)
            for j, ch in enumerate(random_str):
                y[j][i, :] = 0
                y[j][i, characters.find(ch)] = 1
        yield X, y
```

The above is an example of infinitely generating data, we will use this generator to train our model.

# Using generator

The generator is very simple to use, just use the next function. Below is an example of generating 32 data and then displaying the first data. Of course, here we also decode the generated One-Hot encoded data, first convert it to a numpy array. Because the neural network will output a probability of 36 characters, we then convert the number of the four characters with the highest probability into a string.

```py
def decode(y):
    y = np.argmax(np.array(y), axis=2)[:,0]
    return ''.join([characters[x] for x in y])

X, y = next(gen(1))
plt.imshow(X[0])
plt.title(decode(y))
```

# Constructing a deep convolutional neural network

```py
from keras.models import *
from keras.layers import *

input_tensor = Input((height, width, 3))
x = input_tensor
for i in range(4):
    x = Convolution2D(32*2**i, 3, 3, activation='relu')(x)
    x = Convolution2D(32*2**i, 3, 3, activation='relu')(x)
    x = MaxPooling2D((2, 2))(x)

x = Flatten()(x)
x = Dropout(0.25)(x)
x = [Dense(n_class, activation='softmax', name='c%d'%(i+1))(x) for i in range(4)]
model = Model(input=input_tensor, output=x)

model.compile(loss='categorical_crossentropy',
              optimizer='adadelta',
              metrics=['accuracy'])
```

The model structure is simple. The feature extraction part uses two convolutions and a pooling , which is the structure of VGG16. Then we flatten it, then add Dropout to avoid over-fitting problems, and finally connect four classifiers, each of which is 36 neurons, with a probability of 36 characters.

# Model visualization

Thanks to Keras' own visualization, we can use a few lines of code to visualize the structure of the model:

```py
from keras.utils.visualize_util import plot
from IPython.display import Image

plot(model, to_file="model.png", show_shapes=True)
Image('model.png')
```

Here we need to use pydot and graphviz library. The installation method is as follows:

```sh
brew install graphviz
pip install pydot-ng
```

![](https://raw.githubusercontent.com/ypwhs/resources/master/captcha/model.png)

We can see that the shape of the last convolutional layer is `(1, 6, 256)`, and the convolution layer can no longer be added.

# Training model

The training model is the simplest of all the steps, just use `model.fit_generator`. The validation set here uses the same generator. Since the data is randomly generated by the generator, we don't have to think about whether the data will be repeat. Note that this code can take up to an afternoon on your notebook. If you want the model to be more accurate, you can change `nb_epoch` to 10 or 20, but it will take twice as long. Note that we used a little trick here, adding the `nb_worker=2` parameter to let Keras automatically implement multi-process generation of data, to get rid of the shortcomings of Python single-thread efficiency.

```py
model.fit_generator(gen(), samples_per_epoch=51200, nb_epoch=5, 
                    nb_worker=2, pickle_safe=True, 
                    validation_data=gen(), nb_val_samples=1280)
```

# Testing model

```py
X, y = next(gen(1))
y_pred = model.predict(X)
plt.title('real: %s\npred:%s'%(decode(y), decode(y_pred)))
plt.imshow(X[0], cmap='gray')
```

![](https://raw.githubusercontent.com/ypwhs/resources/master/captcha/test_model.png)

# Calculating accuracy of model

```py
from tqdm import tqdm
def evaluate(model, batch_num=20):
    batch_acc = 0
    generator = gen()
    for i in tqdm(range(batch_num)):
        X, y = next(generator)
        y_pred = model.predict(X)
        y_pred = np.argmax(y_pred, axis=2).T
        y_true = np.argmax(y, axis=2).T
        batch_acc += np.mean(map(np.array_equal, y_true, y_pred))
    return batch_acc / batch_num

evaluate(model)
```

A library called tqdm is used here, which is a library of progress bars for real-time feedback. Then we use some numpy calculations to calculate our accuracy. The calculation rule here is that if there is a mistake, then it is not correct. After calculation, the overall accuracy of our model can reach 90% after five generations of training, and further training can achieve higher accuracy.

# Model summary

The size of the model is 16MB. It takes 20 seconds to run 1000 verification codes on my laptop. Of course, the graphics card will be faster. Our recognition rate is 90%, it can be said that this type of verification code is completely cracked.



# Reference

* [http://keras-cn.readthedocs.io/en/latest/getting_started/functional_API/](http://keras-cn.readthedocs.io/en/latest/getting_started/functional_API/)
* [https://github.com/fchollet/keras/blob/master/examples/image_ocr.py](https://github.com/fchollet/keras/blob/master/examples/image_ocr.py)
* [http://cs231n.github.io/convolutional-networks/](http://cs231n.github.io/convolutional-networks/)
